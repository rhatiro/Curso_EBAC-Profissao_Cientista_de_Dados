{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "166f6f33-c507-4fc6-9ebd-9986eb51ea53",
   "metadata": {},
   "source": [
    "[![ebac_logo-data_science.png](https://raw.githubusercontent.com/rhatiro/Curso_EBAC-Profissao_Cientista_de_Dados/main/ebac-course-utils/media/logo/ebac_logo-data_science.png)](https://github.com/rhatiro/Curso_EBAC-Profissao_Cientista_de_Dados)\n",
    "<!-- <img src=\"https://raw.githubusercontent.com/rhatiro/Curso_EBAC-Profissao_Cientista_de_Dados/main/ebac-course-utils/media/logo/ebac_logo-data_science.png\" alt=\"ebac_logo-data_science\"> -->\n",
    "\n",
    "---\n",
    "\n",
    "<!-- # **Profissão: Cientista de Dados** -->\n",
    "### **Módulo 23** | Combinação de modelos I | Exercício 2\n",
    "\n",
    "**Aluno:** [Roberto Hatiro Nishiyama](https://www.linkedin.com/in/rhatiro/)<br>\n",
    "**Data:** 31 de maio de 2023.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb6a816-ff6f-403b-8622-0ca33cea960b",
   "metadata": {},
   "source": [
    "# Tarefa 02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01af968-8131-4047-936f-ee55315b09a4",
   "metadata": {},
   "source": [
    "**1.** Monte um passo a passo para o algoritmo RF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527cc51a-cdf8-44ae-b8d8-93ebce1009e1",
   "metadata": {},
   "source": [
    "> Semelhante ao *Bagging*, o ***Random Forest*** consiste nos seguintes passos:\n",
    "> 1. ***Bootstrap + Feature Selection:*** Assim como no *Bagging*, o *Random Forest* utiliza amostras aleatórias com reposição do conjunto de dados de treinamento original. No entanto, em cada uma dessas amostras, apenas um subconjunto aleatório de variáveis é selecionado (*feature selection*). No caso de problemas de classificação, geralmente é recomendado escolher a raiz quadrada do número total de variáveis, enquanto em problemas de regressão, um terço das variáveis é comumente usado.\n",
    "> 2. **Modelagem com árvores de decisão:** Nesta etapa, um modelo de *Machine Learning*, especificamente uma árvore de decisão, é treinado de forma independente em cada amostra *bootstrap* com as variáveis aleatórias que foram definidas no passo anterior.\n",
    "> 3. **Agregação:** Por fim, os resultados de cada modelo independente (cada árvore de decisão) são agregados para obter uma previsão final. Em problemas de classificação, a agregação é geralmente feita por meio do voto majoritário, em que a classe prevista com mais frequência pelos modelos individuais é selecionada como a classe final. Já em problemas de regressão, a agregação é realizada calculando a média das previsões dos modelos individuais."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805122b5-5f98-4013-bac2-d36ed341325c",
   "metadata": {},
   "source": [
    "**2.** Explique com suas palavras o Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be7b205-08c5-45a8-a29e-45e1c9baf2b5",
   "metadata": {},
   "source": [
    "> ***Random Forest*** pode ser definido como uma extensão do *Bootstrap Aggregating*, conhecido como *Bagging*, que oferece melhorias em desempenho e resultados. Assim como no *Bagging*, o *Random Forest* é um método de combinação de modelos de *Machine Learning*, em que cada modelo é treinado em variações do conjunto de dados original. Essas variações, chamadas de *amostras bootstrap*, consistem em subconjuntos aleatórios do conjunto de dados original, com possíveis repetições, mantendo o mesmo número de linhas. No entanto, o *Random Forest* diferencia-se ao utilizar apenas uma quantidade determinada e aleatória de variáveis em cada modelo, especificamente em modelos de árvore de decisão. Essa abordagem tem o objetivo de reduzir a variância dos resultados e atenuar o risco de *overfitting*. Para obter a previsão final, a agregação dos modelos é realizada de forma semelhante ao *Bagging*, onde a média é utilizada para regressão e votação para classificação."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a54f311-a631-4d9c-a2e0-92064484db82",
   "metadata": {},
   "source": [
    "**3.** Qual a diferença entre Bagging e Random Forest?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd86441-282d-434f-8a6c-c84f668a7a31",
   "metadata": {},
   "source": [
    "> A diferença entre *Bagging* e *Random Forest* está no desempenho e na redução da variância entre os resultados dos modelos. *Bagging* é uma técnica mais geral de combinação de modelos de *Machine Learning* utilizando amostragem aleatória, enquanto *Random Forest* é uma variação mais específica desse método que utiliza árvores de decisão. No *Random Forest*, cada modelo é treinado em subconjuntos aleatórios do conjunto de dados original, com uma quantidade reduzida e aleatória de variáveis consideradas em cada modelo. Essa abordagem aumenta a robustez do modelo e, ao combinar os resultados dos modelos, a previsão final tende a ser mais precisa do que no *Bagging*. Portanto, *Random Forest* é uma extensão aprimorada do *Bagging*, fornecendo um desempenho melhorado e uma redução adicional na variância dos resultados.\n",
    ">\n",
    ">> **\"*Random Forest* funciona melhor que o *Bagging*, pois as árvores amostradas são mais independentes (menor correlação).\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4478db89-7ae8-4216-a600-9f5c97f3cbf0",
   "metadata": {},
   "source": [
    "**4.** (Opcional) Implementar em python o Random Forest\n",
    "> - Bootstrap\n",
    "> - Feature selection\n",
    "> - Modelagem com Decision trees\n",
    "> - Agregação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a698d4e7-cef9-411a-9227-f6a0ce9e5de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import das bibliotecas:\n",
    "\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets        import load_iris\n",
    "from sklearn.datasets        import load_diabetes\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.tree            import DecisionTreeClassifier\n",
    "from sklearn.metrics         import accuracy_score\n",
    "\n",
    "from sklearn.tree            import DecisionTreeRegressor\n",
    "from sklearn.metrics         import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9eebb7d-9eda-475d-87f6-a8565dd80612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier()\n",
      "Accuracy score: 0.96\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    y_test  y_pred\n",
       "0        0       0\n",
       "1        2       2\n",
       "2        1       1\n",
       "3        2       2\n",
       "4        1       1\n",
       "5        2       2\n",
       "6        2       1\n",
       "7        2       2\n",
       "8        1       1\n",
       "9        0       0\n",
       "10       2       2\n",
       "11       2       1\n",
       "12       1       1\n",
       "13       0       0\n",
       "14       0       0\n",
       "15       0       0\n",
       "16       1       1\n",
       "17       1       1\n",
       "18       0       0\n",
       "19       2       2\n",
       "20       2       2\n",
       "21       0       0\n",
       "22       2       2\n",
       "23       2       2\n",
       "24       1       1\n",
       "25       0       0\n",
       "26       0       0\n",
       "27       2       2\n",
       "28       1       1\n",
       "29       0       0\n",
       "30       0       0\n",
       "31       0       0\n",
       "32       0       0\n",
       "33       2       2\n",
       "34       2       2\n",
       "35       1       1\n",
       "36       1       1\n",
       "37       0       0\n",
       "38       2       2\n",
       "39       1       1\n",
       "40       0       0\n",
       "41       2       2\n",
       "42       2       2\n",
       "43       0       0\n",
       "44       2       2\n",
       "45       2       2\n",
       "46       0       0\n",
       "47       1       1\n",
       "48       1       1\n",
       "49       1       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemplo da técnica Random Forest para problemas de classificação:\n",
    "\n",
    "X = load_iris().data\n",
    "y = load_iris().target\n",
    "\n",
    "df = pd.DataFrame(X, columns=load_iris().feature_names)\n",
    "df['target'] = y\n",
    "\n",
    "def rf_classifier(df:pd.DataFrame, \n",
    "                  num_bootstrap_samples:int=3,  # Parâmetro da função que define a quantidade de amostragens para treinamento\n",
    "                  test_size:float=0.25\n",
    "                 ) -> pd.DataFrame:\n",
    "    \n",
    "    df_train, df_test = train_test_split(df, test_size=test_size)\n",
    "    \n",
    "    X_test = df_test.drop(['target'], axis=1)\n",
    "    y_test = df_test['target'].rename('y_test')\n",
    "    \n",
    "    # Dicionário para os resultados das predições de cada modelo\n",
    "    y_pred_bagging = {}\n",
    "\n",
    "    for i in range(num_bootstrap_samples):\n",
    "        # Bootstrap\n",
    "        df_train = df_train.sample(n=len(df_train), \n",
    "                                   replace=True)  # Amostragem COM reposição\n",
    "\n",
    "        X_train = df_train.drop(['target'], axis=1)\n",
    "        # Feature selection\n",
    "        X_train = X_train.sample(n=round(np.sqrt(X_train.shape[1])),  # Cálculo da raiz quadrada da quantidade de variáveis\n",
    "                                 axis=1)\n",
    "        \n",
    "        y_train = df_train['target']\n",
    "        \n",
    "        # Modelagem (base learners)\n",
    "        model = DecisionTreeClassifier()\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Adicionando os resultados do modelo ao dicionário para agregação das predições\n",
    "        y_pred_bagging.update({i:model.predict(X_test[X_train.columns])})\n",
    "    \n",
    "    # Aggregating\n",
    "    y_pred = (pd.DataFrame(y_pred_bagging)\n",
    "                .mode(axis=1)  # Agregando o valor com maior número de aparições nas predições dos modelos\n",
    "                .rename(columns={0:'y_pred'}))\n",
    " \n",
    "    # Resultados\n",
    "    print(model)\n",
    "    print('Accuracy score:', accuracy_score(y_true=y_test, \n",
    "                                            y_pred=y_pred['y_pred']\n",
    "                                           ))\n",
    "\n",
    "    return pd.concat(objs=[y_test.reset_index(drop=True), \n",
    "                           y_pred['y_pred'].astype(int)], \n",
    "                     axis=1)\n",
    "\n",
    "rf_classifier(num_bootstrap_samples=10, df=df, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c44692d5-b1a0-4351-af50-6941709045c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressor()\n",
      "Mean squared error: 4199.046575342466\n",
      "Coefficient of determination: 0.271689234225421\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>155.0</td>\n",
       "      <td>121.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72.0</td>\n",
       "      <td>155.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>197.0</td>\n",
       "      <td>187.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>154.0</td>\n",
       "      <td>141.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>277.0</td>\n",
       "      <td>217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>148.0</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>198.0</td>\n",
       "      <td>123.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>199.0</td>\n",
       "      <td>133.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>270.0</td>\n",
       "      <td>190.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>91.0</td>\n",
       "      <td>163.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_test  y_pred\n",
       "0     155.0   121.3\n",
       "1      72.0   155.2\n",
       "2     197.0   187.5\n",
       "3     154.0   141.5\n",
       "4     277.0   217.0\n",
       "..      ...     ...\n",
       "141   148.0   153.0\n",
       "142   198.0   123.6\n",
       "143   199.0   133.3\n",
       "144   270.0   190.4\n",
       "145    91.0   163.3\n",
       "\n",
       "[146 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemplo da técnica Random Forest para problemas de regressão:\n",
    "\n",
    "X = load_diabetes().data\n",
    "y = load_diabetes().target\n",
    "\n",
    "df = pd.DataFrame(X, columns=load_diabetes().feature_names)\n",
    "df['target'] = y\n",
    "\n",
    "def rf_regressor(df:pd.DataFrame, \n",
    "                 num_bootstrap_samples:int=3,  # Parâmetro da função que define a quantidade de amostragens para treinamento\n",
    "                 test_size:float=0.25\n",
    "                ) -> pd.DataFrame:\n",
    "    \n",
    "    df_train, df_test = train_test_split(df, test_size=test_size)\n",
    "    \n",
    "    X_test = df_test.drop(['target'], axis=1)\n",
    "    y_test = df_test['target'].rename('y_test')\n",
    "    \n",
    "    # Dicionário para os resultados das predições de cada modelo\n",
    "    y_pred_bagging = {}\n",
    "\n",
    "    for i in range(num_bootstrap_samples):\n",
    "        # Bootstrap\n",
    "        df_train = df_train.sample(n=len(df_train), \n",
    "                                   replace=True)  # Amostragem COM reposição\n",
    "\n",
    "        X_train = df_train.drop(['target'], axis=1)\n",
    "        # Feature selection\n",
    "        X_train = X_train.sample(n=round(X_train.shape[1]/3),  # Cálculo da quantidade de variáveis dividida por 3\n",
    "                                 axis=1)\n",
    "        \n",
    "        y_train = df_train['target']\n",
    "\n",
    "        # Modelagem (base learners)\n",
    "        model = DecisionTreeRegressor()\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Adicionando os resultados do modelo ao dicionário para agregação das predições\n",
    "        y_pred_bagging.update({i:model.predict(X_test[X_train.columns])})\n",
    "\n",
    "    # Aggregating\n",
    "    y_pred = (pd.DataFrame(y_pred_bagging)\n",
    "                .mean(axis=1)  # Agregando as predições dos modelos baseando n a média dos resultados\n",
    "                .rename('y_pred'))\n",
    " \n",
    "    # Resultados\n",
    "    print(model)\n",
    "    print('Mean squared error:', mean_squared_error(y_true=y_test, \n",
    "                                                   y_pred=y_pred))\n",
    "    print('Coefficient of determination:', r2_score(y_true=y_test, \n",
    "                                                    y_pred=y_pred))\n",
    "    \n",
    "    return pd.concat(objs=[y_test.reset_index(drop=True), \n",
    "                           y_pred], \n",
    "                     axis=1)\n",
    "    \n",
    "rf_regressor(num_bootstrap_samples=10, df=df, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afea5b5-6bed-4c12-adf1-988ce95e0db1",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
